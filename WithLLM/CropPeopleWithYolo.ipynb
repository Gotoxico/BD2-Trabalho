{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26ab41d7",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db236849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "from typing import List, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Detector: ultralytics YOLO\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453dac8",
   "metadata": {},
   "source": [
    "Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FRAMES_FOLDER = \"../HighResImage\" \n",
    "OUTPUT_CROPS_FOLDER = \"CroppedPersonsHighResTeste\"\n",
    "\n",
    "YOLO_WEIGHTS = \"../yolo11n.pt\" #Idealmente utilizar a versão mais recente e a \"n\", pois é mais leve \n",
    "YOLO_CONF = 0.35                           \n",
    "CAMERA_ID = 1\n",
    "\n",
    "IOU_MATCH_THRESHOLD = 0.3                 \n",
    "MIN_BOX_AREA = 400                         \n",
    "ATTR_TOP_K = 2\n",
    "ATTR_CONF_THRESHOLD = 0.05\n",
    "\n",
    "FRAME_LIMIT = 1000 #Limitar número de frames processados (Bom para testes)\n",
    "\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dfcbaa",
   "metadata": {},
   "source": [
    "Funções de apoio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e84d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apenas para make sure diretório existe\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "#Para listar files com frames dentro de folder\n",
    "def list_frame_files(input_folder: str):\n",
    "    files = []\n",
    "    for root, _, filenames in os.walk(input_folder):\n",
    "        for f in sorted(filenames):\n",
    "            if os.path.splitext(f)[1].lower() in IMAGE_EXTS:\n",
    "                files.append(os.path.join(root, f))\n",
    "    return files\n",
    "\n",
    "#Capturar timestamp do filename frame\n",
    "def parse_timestamp_from_filename(fname: str):\n",
    "    base = os.path.basename(fname)\n",
    "    m = re.search(r\"(\\d{4})[-_]?(\\d{2})[-_]?(\\d{2})[_T\\-]?(\\d{2})[:_]?(\\d{2})[:_]?(\\d{2})\", base)\n",
    "    if m:\n",
    "        year, mon, day, h, mn, s = m.groups()\n",
    "        try:\n",
    "            dt = datetime.datetime(int(year), int(mon), int(day), int(h), int(mn), int(s))\n",
    "            return dt.isoformat()\n",
    "        except Exception:\n",
    "            pass\n",
    "    m2 = re.search(r\"(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2})\", base)\n",
    "    if m2:\n",
    "        return m2.group(1)\n",
    "    ts = os.path.getmtime(fname)\n",
    "    return datetime.datetime.fromtimestamp(ts).isoformat()\n",
    "\n",
    "# Calcula o IoU (Intersection over Union) entre dois bounding boxes.\n",
    "# Retorna um valor entre 0 e 1 que indica a sobreposição das caixas.\n",
    "def iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interW = max(0, xB - xA)\n",
    "    interH = max(0, yB - yA)\n",
    "    interArea = interW * interH\n",
    "    if interArea == 0:\n",
    "        return 0.0\n",
    "    boxAArea = max(1.0, (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]))\n",
    "    boxBArea = max(1.0, (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]))\n",
    "    return interArea / float(boxAArea + boxBArea - interArea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c884a",
   "metadata": {},
   "source": [
    "Tracker baseado em IoU para dar ID único para indivíduos/grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e77dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTracker:\n",
    "    \"\"\"\n",
    "    Rastreador simples baseado em IoU (Intersection over Union).\n",
    "\n",
    "    A cada frame:\n",
    "      - Associa detecções novas a objetos existentes com base no IoU.\n",
    "      - Atribui IDs únicos a novos objetos.\n",
    "      - Remove objetos que sumiram há muitos frames.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, iou_threshold=0.3, max_lost=30):\n",
    "        self.next_id = 1\n",
    "        self.tracks = {}\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.max_lost = max_lost\n",
    "\n",
    "    \"\"\"\n",
    "    Atualiza os rastros com as detecções do frame atual.\n",
    "    Retorna uma lista de tuplas (track_id, bounding_box).\n",
    "    \"\"\"\n",
    "    def update(self, detections: List[Tuple[float, float, float, float]], frame_idx: int):\n",
    "        assignments = []\n",
    "        unmatched_dets = set(range(len(detections)))\n",
    "        for tid, info in list(self.tracks.items()):\n",
    "            best_i = -1\n",
    "            best_iou = 0.0\n",
    "            for di in list(unmatched_dets):\n",
    "                val = iou(info['box'], detections[di])\n",
    "                if val > best_iou:\n",
    "                    best_iou = val\n",
    "                    best_i = di\n",
    "            if best_i != -1 and best_iou >= self.iou_threshold:\n",
    "                self.tracks[tid]['box'] = detections[best_i]\n",
    "                self.tracks[tid]['last_seen'] = frame_idx\n",
    "                self.tracks[tid]['lost'] = 0\n",
    "                assignments.append((tid, detections[best_i]))\n",
    "                unmatched_dets.remove(best_i)\n",
    "            else:\n",
    "                self.tracks[tid]['lost'] += 1\n",
    "        to_delete = [tid for tid, info in self.tracks.items() if info['lost'] > self.max_lost]\n",
    "        for tid in to_delete:\n",
    "            del self.tracks[tid]\n",
    "        for di in sorted(unmatched_dets):\n",
    "            tid = self.next_id\n",
    "            self.next_id += 1\n",
    "            self.tracks[tid] = {'box': detections[di], 'last_seen': frame_idx, 'lost': 0}\n",
    "            assignments.append((tid, detections[di]))\n",
    "        return assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8353f51",
   "metadata": {},
   "source": [
    "Detector de indivíduos/grupos baseado em YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50339c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector:\n",
    "    def __init__(self, weights: str = None, conf: float = 0.25, device: str = \"cpu\"):\n",
    "        self.device = device\n",
    "        if weights:\n",
    "            self.model = YOLO(weights)\n",
    "        else:\n",
    "            self.model = YOLO(\"yolov8n\")\n",
    "        self.conf = conf\n",
    "\n",
    "    \"\"\"\n",
    "    Detecta todos os objetos que YOLO foi treinado para detectar e cria registros.\n",
    "    \"\"\"\n",
    "    def detect(self, image: np.ndarray):\n",
    "        res = self.model.predict(image, imgsz=640, conf=self.conf, verbose=False, device=self.device)\n",
    "        results = res[0]\n",
    "        detections = []\n",
    "        if getattr(results, 'boxes', None) is not None:\n",
    "            boxes = results.boxes.xyxy.cpu().numpy()\n",
    "            scores = results.boxes.conf.cpu().numpy()\n",
    "            cls = results.boxes.cls.cpu().numpy().astype(int)\n",
    "            names = getattr(self.model, \"names\", None)\n",
    "            for b, s, c in zip(boxes, scores, cls):\n",
    "                detections.append({\n",
    "                    'bbox': [float(b[0]), float(b[1]), float(b[2]), float(b[3])],\n",
    "                    'confidence': float(s),\n",
    "                    'class_id': int(c),\n",
    "                    'class_name': names[int(c)] if names is not None and int(c) in names else str(int(c))\n",
    "                })\n",
    "        return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b737887",
   "metadata": {},
   "source": [
    "Pipeline principal para recortar pessoas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5a1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline():\n",
    "    ensure_dir(OUTPUT_CROPS_FOLDER)\n",
    "\n",
    "    # Tentar utilizar GPU CUDA, se tiver\n",
    "    try:\n",
    "        import torch\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    except Exception:\n",
    "        device = \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Inicializando módulos\n",
    "    detector = Detector(weights=YOLO_WEIGHTS, conf=YOLO_CONF, device=device)\n",
    "    tracker = SimpleTracker(iou_threshold=IOU_MATCH_THRESHOLD, max_lost=30)\n",
    "\n",
    "    frame_files = list_frame_files(INPUT_FRAMES_FOLDER)\n",
    "    # Para limitar quantidade de frames processados (útil para testes rápidos)\n",
    "    if FRAME_LIMIT:\n",
    "        frame_files = frame_files[:FRAME_LIMIT]\n",
    "    if not frame_files:\n",
    "        print(\"Frames não foram encontrados em \", INPUT_FRAMES_FOLDER)\n",
    "        return\n",
    "\n",
    "    print(f\"Encontrou {len(frame_files)} frames, processando...\")\n",
    "\n",
    "    frame_idx = 0\n",
    "    saved_track_ids = set()  # guarda IDs já salvos (somente um frame por ID)\n",
    "\n",
    "    for frame_path in frame_files:\n",
    "        frame_idx += 1\n",
    "        pil = Image.open(frame_path).convert(\"RGB\")\n",
    "        img_np = np.array(pil)\n",
    "\n",
    "        dets = detector.detect(img_np)\n",
    "\n",
    "        # Utilizando apenas bounding boxes com pessoas\n",
    "        person_dets_xyxy = []\n",
    "        for d in dets:\n",
    "            name = d.get('class_name', '').lower()\n",
    "            if name in (\"person\", \"people\", \"human\") or int(d.get('class_id', -1)) == 0:\n",
    "                x1, y1, x2, y2 = [int(round(v)) for v in d['bbox']]\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                if area >= MIN_BOX_AREA:\n",
    "                    person_dets_xyxy.append([x1, y1, x2, y2])\n",
    "\n",
    "        assignments = tracker.update(person_dets_xyxy, frame_idx)\n",
    "        timestamp = parse_timestamp_from_filename(frame_path)\n",
    "        frame_base = os.path.splitext(os.path.basename(frame_path))[0]\n",
    "\n",
    "        # Para cada track: salva APENAS se ainda não salvamos aquele track_id\n",
    "        for track_id, box in assignments:\n",
    "            if track_id in saved_track_ids:\n",
    "                continue  # já salvamos esse ID anteriormente\n",
    "\n",
    "            x1, y1, x2, y2 = [int(v) for v in box]\n",
    "            crop = pil.crop((x1, y1, x2, y2))\n",
    "\n",
    "            fname_ts = timestamp.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "            crop_fname = f\"cam{CAMERA_ID}_trk{track_id}_{frame_base}_{fname_ts}.jpg\"\n",
    "            crop_path = os.path.join(OUTPUT_CROPS_FOLDER, crop_fname)\n",
    "            try:\n",
    "                crop.save(crop_path, format=\"JPEG\", quality=90)\n",
    "                saved_track_ids.add(track_id)\n",
    "            except Exception as e:\n",
    "                print(f\"Falha ao salvar crop para track {track_id}:\", e)\n",
    "\n",
    "        # Simulando TQDM\n",
    "        if frame_idx % 50 == 0:\n",
    "            print(f\"Processou {frame_idx}/{len(frame_files)} frames\")\n",
    "\n",
    "    print(f\"Pronto. Crops de IDs únicos salvos em: {OUTPUT_CROPS_FOLDER} (total salvos: {len(saved_track_ids)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a46269",
   "metadata": {},
   "source": [
    "Rodar main pipeline principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70470693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Encontrou 1 frames, processando...\n",
      "Pronto. Crops de IDs únicos salvos em: CroppedPersonsHighResTeste (total salvos: 9)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
